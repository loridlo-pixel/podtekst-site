{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/loridlo-pixel/podtekst-site/blob/main/Retrieval_based_Voice_Conversion_WebUI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QCADq5dOXUL"
      },
      "source": [
        "# [Retrieval-based-Voice-Conversion-WebUI](https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI) Training notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFFCx5J80SGa"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/blob/main/Retrieval_based_Voice_Conversion_WebUI.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmFP6bN9dvOq"
      },
      "outputs": [],
      "source": [
        "# @title Êü•ÁúãÊòæÂç°\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwu07JgqoFON"
      },
      "outputs": [],
      "source": [
        "# @title ÊåÇËΩΩË∞∑Ê≠å‰∫ëÁõò\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjddIFr1oS3W"
      },
      "outputs": [],
      "source": [
        "# @title ÂÆâË£Ö‰æùËµñ\n",
        "!apt-get -y install build-essential python3-dev ffmpeg\n",
        "!pip3 install --upgrade setuptools wheel\n",
        "!pip3 install --upgrade pip\n",
        "!pip3 install faiss-cpu==1.7.2 fairseq gradio==3.14.0 ffmpeg ffmpeg-python praat-parselmouth pyworld numpy==1.23.5 numba==0.56.4 librosa==0.9.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ge_97mfpgqTm"
      },
      "outputs": [],
      "source": [
        "# @title ÂÖãÈöÜ‰ªìÂ∫ì\n",
        "\n",
        "!git clone --depth=1 -b stable https://github.com/fumiama/Retrieval-based-Voice-Conversion-WebUI\n",
        "%cd /content/Retrieval-based-Voice-Conversion-WebUI\n",
        "!mkdir -p pretrained uvr5_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLDEZADkvlw1"
      },
      "outputs": [],
      "source": [
        "# @title Êõ¥Êñ∞‰ªìÂ∫ìÔºà‰∏ÄËà¨Êó†ÈúÄÊâßË°åÔºâ\n",
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqE0PrnuRqI2"
      },
      "outputs": [],
      "source": [
        "# @title ÂÆâË£Öaria2\n",
        "!apt -y install -qq aria2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UG3XpUwEomUz"
      },
      "outputs": [],
      "source": [
        "# @title ‰∏ãËΩΩÂ∫ïÊ®°\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/D32k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o D32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/D40k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o D40k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/D48k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o D48k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/G32k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o G32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/G40k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o G40k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/G48k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o G48k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0D32k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o f0D32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0D40k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o f0D40k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0D48k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o f0D48k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0G32k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o f0G32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0G40k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o f0G40k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0G48k.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/pretrained -o f0G48k.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HugjmZqZRuiF"
      },
      "outputs": [],
      "source": [
        "# @title ‰∏ãËΩΩ‰∫∫Â£∞ÂàÜÁ¶ªÊ®°Âûã\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/uvr5_weights/HP2-‰∫∫Â£∞vocals+Èùû‰∫∫Â£∞instrumentals.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/uvr5_weights -o HP2-‰∫∫Â£∞vocals+Èùû‰∫∫Â£∞instrumentals.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/uvr5_weights/HP5-‰∏ªÊóãÂæã‰∫∫Â£∞vocals+ÂÖ∂‰ªñinstrumentals.pth -d /content/Retrieval-based-Voice-Conversion-WebUI/uvr5_weights -o HP5-‰∏ªÊóãÂæã‰∫∫Â£∞vocals+ÂÖ∂‰ªñinstrumentals.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RCaT9FTR0ej"
      },
      "outputs": [],
      "source": [
        "# @title ‰∏ãËΩΩhubert_base\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/hubert_base.pt -d /content/Retrieval-based-Voice-Conversion-WebUI -o hubert_base.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6BvGCvgOXUc"
      },
      "outputs": [],
      "source": [
        "# @title #‰∏ãËΩΩrmvpeÊ®°Âûã\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/rmvpe.pt -d /content/Retrieval-based-Voice-Conversion-WebUI -o rmvpe.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mwk7Q0Loqzjx"
      },
      "outputs": [],
      "source": [
        "# @title ‰ªéË∞∑Ê≠å‰∫ëÁõòÂä†ËΩΩÊâìÂåÖÂ•ΩÁöÑÊï∞ÊçÆÈõÜÂà∞/content/dataset\n",
        "\n",
        "# @markdown Êï∞ÊçÆÈõÜ‰ΩçÁΩÆ\n",
        "DATASET = (\n",
        "    \"/content/drive/MyDrive/dataset/lulu20230327_32k.zip\"  # @param {type:\"string\"}\n",
        ")\n",
        "\n",
        "!mkdir -p /content/dataset\n",
        "!unzip -d /content/dataset -B {DATASET}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDlFxWHWEynD"
      },
      "outputs": [],
      "source": [
        "# @title ÈáçÂëΩÂêçÊï∞ÊçÆÈõÜ‰∏≠ÁöÑÈáçÂêçÊñá‰ª∂\n",
        "!ls -a /content/dataset/\n",
        "!rename 's/(\\w+)\\.(\\w+)~(\\d*)/$1_$3.$2/' /content/dataset/*.*~*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vh6vphDwO0b"
      },
      "outputs": [],
      "source": [
        "# @title ÂêØÂä®web\n",
        "%cd /content/Retrieval-based-Voice-Conversion-WebUI\n",
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir /content/Retrieval-based-Voice-Conversion-WebUI/logs\n",
        "!python3 infer-web.py --colab --pycmd python3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgJuNeAwx5Y_"
      },
      "outputs": [],
      "source": [
        "# @title ÊâãÂä®Â∞ÜËÆ≠ÁªÉÂêéÁöÑÊ®°ÂûãÊñá‰ª∂Â§á‰ªΩÂà∞Ë∞∑Ê≠å‰∫ëÁõò\n",
        "# @markdown ÈúÄË¶ÅËá™Â∑±Êü•ÁúãlogsÊñá‰ª∂Â§π‰∏ãÊ®°ÂûãÁöÑÊñá‰ª∂ÂêçÔºåÊâãÂä®‰øÆÊîπ‰∏ãÊñπÂëΩ‰ª§Êú´Â∞æÁöÑÊñá‰ª∂Âêç\n",
        "\n",
        "# @markdown Ê®°ÂûãÂêç\n",
        "MODELNAME = \"lulu\"  # @param {type:\"string\"}\n",
        "# @markdown Ê®°Âûãepoch\n",
        "MODELEPOCH = 9600  # @param {type:\"integer\"}\n",
        "\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/G_{MODELEPOCH}.pth /content/drive/MyDrive/{MODELNAME}_D_{MODELEPOCH}.pth\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/D_{MODELEPOCH}.pth /content/drive/MyDrive/{MODELNAME}_G_{MODELEPOCH}.pth\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/added_*.index /content/drive/MyDrive/\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/total_*.npy /content/drive/MyDrive/\n",
        "\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/weights/{MODELNAME}.pth /content/drive/MyDrive/{MODELNAME}{MODELEPOCH}.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVQoLQJXS7WX"
      },
      "outputs": [],
      "source": [
        "# @title ‰ªéË∞∑Ê≠å‰∫ëÁõòÊÅ¢Â§çpth\n",
        "# @markdown ÈúÄË¶ÅËá™Â∑±Êü•ÁúãlogsÊñá‰ª∂Â§π‰∏ãÊ®°ÂûãÁöÑÊñá‰ª∂ÂêçÔºåÊâãÂä®‰øÆÊîπ‰∏ãÊñπÂëΩ‰ª§Êú´Â∞æÁöÑÊñá‰ª∂Âêç\n",
        "\n",
        "# @markdown Ê®°ÂûãÂêç\n",
        "MODELNAME = \"lulu\"  # @param {type:\"string\"}\n",
        "# @markdown Ê®°Âûãepoch\n",
        "MODELEPOCH = 7500  # @param {type:\"integer\"}\n",
        "\n",
        "!mkdir -p /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}\n",
        "\n",
        "!cp /content/drive/MyDrive/{MODELNAME}_D_{MODELEPOCH}.pth /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/G_{MODELEPOCH}.pth\n",
        "!cp /content/drive/MyDrive/{MODELNAME}_G_{MODELEPOCH}.pth /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/D_{MODELEPOCH}.pth\n",
        "!cp /content/drive/MyDrive/*.index /content/\n",
        "!cp /content/drive/MyDrive/*.npy /content/\n",
        "!cp /content/drive/MyDrive/{MODELNAME}{MODELEPOCH}.pth /content/Retrieval-based-Voice-Conversion-WebUI/weights/{MODELNAME}.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKAyuKb9J6dz"
      },
      "outputs": [],
      "source": [
        "# @title ÊâãÂä®È¢ÑÂ§ÑÁêÜÔºà‰∏çÊé®ËçêÔºâ\n",
        "# @markdown Ê®°ÂûãÂêç\n",
        "MODELNAME = \"lulu\"  # @param {type:\"string\"}\n",
        "# @markdown ÈááÊ†∑Áéá\n",
        "BITRATE = 48000  # @param {type:\"integer\"}\n",
        "# @markdown ‰ΩøÁî®ÁöÑËøõÁ®ãÊï∞\n",
        "THREADCOUNT = 8  # @param {type:\"integer\"}\n",
        "\n",
        "!python3 trainset_preprocess_pipeline_print.py /content/dataset {BITRATE} {THREADCOUNT} logs/{MODELNAME} True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrxJqzAUKmPJ"
      },
      "outputs": [],
      "source": [
        "# @title ÊâãÂä®ÊèêÂèñÁâπÂæÅÔºà‰∏çÊé®ËçêÔºâ\n",
        "# @markdown Ê®°ÂûãÂêç\n",
        "MODELNAME = \"lulu\"  # @param {type:\"string\"}\n",
        "# @markdown ‰ΩøÁî®ÁöÑËøõÁ®ãÊï∞\n",
        "THREADCOUNT = 8  # @param {type:\"integer\"}\n",
        "# @markdown Èü≥È´òÊèêÂèñÁÆóÊ≥ï\n",
        "ALGO = \"harvest\"  # @param {type:\"string\"}\n",
        "\n",
        "!python3 extract_f0_print.py logs/{MODELNAME} {THREADCOUNT} {ALGO}\n",
        "\n",
        "!python3 extract_feature_print.py cpu 1 0 0 logs/{MODELNAME} True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMLPLKOaKj58"
      },
      "outputs": [],
      "source": [
        "# @title ÊâãÂä®ËÆ≠ÁªÉÔºà‰∏çÊé®ËçêÔºâ\n",
        "# @markdown Ê®°ÂûãÂêç\n",
        "MODELNAME = \"lulu\"  # @param {type:\"string\"}\n",
        "# @markdown ‰ΩøÁî®ÁöÑGPU\n",
        "USEGPU = \"0\"  # @param {type:\"string\"}\n",
        "# @markdown ÊâπÂ§ßÂ∞è\n",
        "BATCHSIZE = 32  # @param {type:\"integer\"}\n",
        "# @markdown ÂÅúÊ≠¢ÁöÑepoch\n",
        "MODELEPOCH = 3200  # @param {type:\"integer\"}\n",
        "# @markdown ‰øùÂ≠òepochÈó¥Èöî\n",
        "EPOCHSAVE = 100  # @param {type:\"integer\"}\n",
        "# @markdown ÈááÊ†∑Áéá\n",
        "MODELSAMPLE = \"48k\"  # @param {type:\"string\"}\n",
        "# @markdown ÊòØÂê¶ÁºìÂ≠òËÆ≠ÁªÉÈõÜ\n",
        "CACHEDATA = 1  # @param {type:\"integer\"}\n",
        "# @markdown ÊòØÂê¶‰ªÖ‰øùÂ≠òÊúÄÊñ∞ÁöÑckptÊñá‰ª∂\n",
        "ONLYLATEST = 0  # @param {type:\"integer\"}\n",
        "\n",
        "!python3 train_nsf_sim_cache_sid_load_pretrain.py -e lulu -sr {MODELSAMPLE} -f0 1 -bs {BATCHSIZE} -g {USEGPU} -te {MODELEPOCH} -se {EPOCHSAVE} -pg pretrained/f0G{MODELSAMPLE}.pth -pd pretrained/f0D{MODELSAMPLE}.pth -l {ONLYLATEST} -c {CACHEDATA}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haYA81hySuDl"
      },
      "outputs": [],
      "source": [
        "# @title Âà†Èô§ÂÖ∂ÂÆÉpthÔºåÂè™ÁïôÈÄâ‰∏≠ÁöÑÔºàÊÖéÁÇπÔºå‰ªîÁªÜÁúã‰ª£Á†ÅÔºâ\n",
        "# @markdown Ê®°ÂûãÂêç\n",
        "MODELNAME = \"lulu\"  # @param {type:\"string\"}\n",
        "# @markdown ÈÄâ‰∏≠Ê®°Âûãepoch\n",
        "MODELEPOCH = 9600  # @param {type:\"integer\"}\n",
        "\n",
        "!echo \"Â§á‰ªΩÈÄâ‰∏≠ÁöÑÊ®°Âûã„ÄÇ„ÄÇ„ÄÇ\"\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/G_{MODELEPOCH}.pth /content/{MODELNAME}_D_{MODELEPOCH}.pth\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/D_{MODELEPOCH}.pth /content/{MODELNAME}_G_{MODELEPOCH}.pth\n",
        "\n",
        "!echo \"Ê≠£Âú®Âà†Èô§„ÄÇ„ÄÇ„ÄÇ\"\n",
        "!ls /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}\n",
        "!rm /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/*.pth\n",
        "\n",
        "!echo \"ÊÅ¢Â§çÈÄâ‰∏≠ÁöÑÊ®°Âûã„ÄÇ„ÄÇ„ÄÇ\"\n",
        "!mv /content/{MODELNAME}_D_{MODELEPOCH}.pth /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/G_{MODELEPOCH}.pth\n",
        "!mv /content/{MODELNAME}_G_{MODELEPOCH}.pth /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/D_{MODELEPOCH}.pth\n",
        "\n",
        "!echo \"Âà†Èô§ÂÆåÊàê\"\n",
        "!ls /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhSiPTVPoIRh"
      },
      "outputs": [],
      "source": [
        "# @title Ê∏ÖÈô§È°πÁõÆ‰∏ãÊâÄÊúâÊñá‰ª∂ÔºåÂè™ÁïôÈÄâ‰∏≠ÁöÑÊ®°ÂûãÔºàÊÖéÁÇπÔºå‰ªîÁªÜÁúã‰ª£Á†ÅÔºâ\n",
        "# @markdown Ê®°ÂûãÂêç\n",
        "MODELNAME = \"lulu\"  # @param {type:\"string\"}\n",
        "# @markdown ÈÄâ‰∏≠Ê®°Âûãepoch\n",
        "MODELEPOCH = 9600  # @param {type:\"integer\"}\n",
        "\n",
        "!echo \"Â§á‰ªΩÈÄâ‰∏≠ÁöÑÊ®°Âûã„ÄÇ„ÄÇ„ÄÇ\"\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/G_{MODELEPOCH}.pth /content/{MODELNAME}_D_{MODELEPOCH}.pth\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/D_{MODELEPOCH}.pth /content/{MODELNAME}_G_{MODELEPOCH}.pth\n",
        "\n",
        "!echo \"Ê≠£Âú®Âà†Èô§„ÄÇ„ÄÇ„ÄÇ\"\n",
        "!ls /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}\n",
        "!rm -rf /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/*\n",
        "\n",
        "!echo \"ÊÅ¢Â§çÈÄâ‰∏≠ÁöÑÊ®°Âûã„ÄÇ„ÄÇ„ÄÇ\"\n",
        "!mv /content/{MODELNAME}_D_{MODELEPOCH}.pth /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/G_{MODELEPOCH}.pth\n",
        "!mv /content/{MODELNAME}_G_{MODELEPOCH}.pth /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/D_{MODELEPOCH}.pth\n",
        "\n",
        "!echo \"Âà†Èô§ÂÆåÊàê\"\n",
        "!ls /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 1Ô∏è‚É£ –°–∫–∞—á–∏–≤–∞–µ–º RVC WebUI\n",
        "# ===========================\n",
        "!git clone https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI.git\n",
        "import os\n",
        "os.chdir(\"/content/Retrieval-based-Voice-Conversion-WebUI\")\n",
        "\n",
        "# ===========================\n",
        "# 2Ô∏è‚É£ –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏\n",
        "# ===========================\n",
        "!pip install -q -r requirements.txt\n",
        "!pip install -q torch torchaudio librosa scipy onnx onnxruntime\n",
        "\n",
        "# ===========================\n",
        "# 3Ô∏è‚É£ –ü–æ–¥–∫–ª—é—á–∞–µ–º GPU\n",
        "# ===========================\n",
        "import torch\n",
        "print(\"GPU –¥–æ—Å—Ç—É–ø–µ–Ω:\", torch.cuda.is_available())\n",
        "\n",
        "# ===========================\n",
        "# 4Ô∏è‚É£ –ó–∞–≥—Ä—É–∂–∞–µ–º HuBERT –∏ –¥–∞—Ç–∞—Å–µ—Ç\n",
        "# ===========================\n",
        "# –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Å–≤–æ–∏ —Ñ–∞–π–ª—ã HuBERT .onnx –≤ /content/hubert-onnx/hubert_base.onnx\n",
        "# –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Å–≤–æ–∏ WAV-—Ñ–∞–π–ª—ã –≤ /content/mydataset\n",
        "dataset_path = \"/content/mydataset\"\n",
        "hubert_path = \"/content/hubert-onnx/hubert_base.onnx\"\n",
        "os.makedirs(\"/content/hubert-onnx\", exist_ok=True)\n",
        "os.makedirs(\"/content/mydataset\", exist_ok=True)\n",
        "\n",
        "# ===========================\n",
        "# 5Ô∏è‚É£ –°–æ–∑–¥–∞—ë–º filelist.txt\n",
        "# ===========================\n",
        "filelist_path = \"/content/filelist.txt\"\n",
        "wav_files = [f for f in os.listdir(dataset_path) if f.endswith(\".wav\")]\n",
        "with open(filelist_path, \"w\") as f:\n",
        "    for file in wav_files:\n",
        "        f.write(f\"{dataset_path}/{file}|0\\n\")\n",
        "print(f\"‚úÖ filelist.txt —Å–æ–∑–¥–∞–Ω, —Å—Ç—Ä–æ–∫: {len(wav_files)}\")\n",
        "\n",
        "# ===========================\n",
        "# 6Ô∏è‚É£ –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É –¥–ª—è —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤\n",
        "# ===========================\n",
        "output_dir = \"/content/checkpoints_rvc\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# ===========================\n",
        "# 7Ô∏è‚É£ –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è RVC\n",
        "# ===========================\n",
        "!python infer/modules/train/train.py \\\n",
        "-se 5 -te 50 -e {output_dir} \\\n",
        "-sr 44100 -v v1 -f0 True -l False -c False \\\n",
        "--train_files {filelist_path} \\\n",
        "--hubert_model_path {hubert_path}\n"
      ],
      "metadata": {
        "id": "l0S3b_qUP5U6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()\n",
        "!nvidia-smi\n"
      ],
      "metadata": {
        "id": "JDWEzVokYEDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python infer/modules/train/preprocess.py\n",
        "!python infer/modules/train/extract_feature_print.py\n"
      ],
      "metadata": {
        "id": "X2Fm4XqAYTL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!ls\n"
      ],
      "metadata": {
        "id": "AieKcFLcYkN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI.git\n"
      ],
      "metadata": {
        "id": "8SNxBVkXYw0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "id": "O-qsexO5Y10u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls Retrieval-based-Voice-Conversion-WebUI/infer/modules/train\n"
      ],
      "metadata": {
        "id": "ALDyTcgIY5lN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Retrieval-based-Voice-Conversion-WebUI\n"
      ],
      "metadata": {
        "id": "xzBy7be0ZFoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python infer/modules/train/preprocess.py \\\n",
        "  /content/ \\\n",
        "  40000 \\\n",
        "  2 \\\n",
        "  my_experiment \\\n",
        "  False\n",
        "\n"
      ],
      "metadata": {
        "id": "w0G3Y-vJZ4KG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/wavs\n"
      ],
      "metadata": {
        "id": "2SsqdiHubdzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# —Å–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É –¥–ª—è RVC\n",
        "!mkdir /content/wavs\n",
        "\n",
        "# –ø–µ—Ä–µ–º–µ—â–∞–µ–º –≤—Å–µ WAV –∏–∑ –∫–æ—Ä–Ω—è –≤ –ø–∞–ø–∫—É\n",
        "!mv /content/*.wav /content/wavs/\n"
      ],
      "metadata": {
        "id": "k70HER7db1NG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # –≤—ã–±—Ä–∞—Ç—å WAV\n",
        "\n",
        "import os\n",
        "os.makedirs(\"/content/wavs\", exist_ok=True)\n",
        "\n",
        "for name in uploaded.keys():\n",
        "    os.rename(name, f\"/content/wavs/{name}\")\n"
      ],
      "metadata": {
        "id": "l_L5EPBAcJDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python infer/modules/train/preprocess.py /content/wavs 40000 2 my_experiment False\n"
      ],
      "metadata": {
        "id": "GbebGfsbdHn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 0. –ë–ê–ó–û–í–ê–Ø –ü–û–î–ì–û–¢–û–í–ö–ê\n",
        "# =========================\n",
        "import os\n",
        "\n",
        "%cd /content\n",
        "!apt-get update -y\n",
        "!apt-get install -y ffmpeg\n",
        "\n",
        "!pip install --upgrade pip setuptools wheel --no-cache-dir\n",
        "\n",
        "# =========================\n",
        "# 1. TORCH (CUDA 11.8 ‚Äî –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è Colab)\n",
        "# =========================\n",
        "!pip install torch torchvision torchaudio \\\n",
        "  --index-url https://download.pytorch.org/whl/cu118 \\\n",
        "  --no-cache-dir\n",
        "\n",
        "# =========================\n",
        "# 2. –ö–†–ò–¢–ò–ß–ù–´–ï –ó–ê–í–ò–°–ò–ú–û–°–¢–ò RVC\n",
        "# =========================\n",
        "!pip install \\\n",
        "  ffmpeg-python \\\n",
        "  av \\\n",
        "  librosa \\\n",
        "  soundfile \\\n",
        "  numpy \\\n",
        "  scipy \\\n",
        "  tqdm \\\n",
        "  numba \\\n",
        "  faiss-cpu \\\n",
        "  praat-parselmouth \\\n",
        "  pyworld \\\n",
        "  noisereduce \\\n",
        "  tensorboard \\\n",
        "  --no-cache-dir\n",
        "\n",
        "# =========================\n",
        "# 3. –ö–õ–û–ù–ò–†–£–ï–ú RVC\n",
        "# =========================\n",
        "RVC_PATH = \"/content/Retrieval-based-Voice-Conversion-WebUI\"\n",
        "\n",
        "if not os.path.exists(RVC_PATH):\n",
        "    !git clone https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI.git\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è RVC —É–∂–µ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω\")\n",
        "\n",
        "# =========================\n",
        "# 4. –°–û–ó–î–ê–Å–ú –ü–ê–ü–ö–ò\n",
        "# =========================\n",
        "os.makedirs(\"/content/wavs\", exist_ok=True)\n",
        "os.makedirs(f\"{RVC_PATH}/logs\", exist_ok=True)\n",
        "\n",
        "# =========================\n",
        "# 5. –ó–ê–ì–†–£–ó–ö–ê WAV\n",
        "# =========================\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for name in uploaded.keys():\n",
        "    dst = f\"/content/wavs/{name}\"\n",
        "    if os.path.exists(dst):\n",
        "        os.remove(dst)\n",
        "    os.rename(name, dst)\n",
        "\n",
        "print(\"‚úÖ WAV —Ñ–∞–π–ª—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ /content/wavs\")\n",
        "\n",
        "# =========================\n",
        "# 6. –ü–†–û–í–ï–†–ö–ê TRAIN-–ú–û–î–£–õ–ï–ô\n",
        "# =========================\n",
        "train_base = f\"{RVC_PATH}/infer/modules/train\"\n",
        "\n",
        "needed = [\n",
        "    \"preprocess.py\",\n",
        "    \"extract_feature_print.py\",\n",
        "    \"train.py\"\n",
        "]\n",
        "\n",
        "missing = [f for f in needed if not os.path.exists(f\"{train_base}/{f}\")]\n",
        "\n",
        "if missing:\n",
        "    print(\"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ñ–∞–π–ª—ã:\", missing)\n",
        "else:\n",
        "    print(\"‚úÖ –í—Å–µ train-—Ñ–∞–π–ª—ã –Ω–∞ –º–µ—Å—Ç–µ\")\n",
        "\n",
        "# =========================\n",
        "# 7. –ü–†–û–í–ï–†–ö–ê –ö–†–ò–¢–ò–ß–ù–´–• –ò–ú–ü–û–†–¢–û–í\n",
        "# =========================\n",
        "import av, ffmpeg, numpy, torch\n",
        "\n",
        "print(\"‚úÖ av / ffmpeg / numpy / torch –∏–º–ø–æ—Ä—Ç–∏—Ä—É—é—Ç—Å—è\")\n",
        "print(\"üî• –°–ò–°–¢–ï–ú–ê –ì–û–¢–û–í–ê –ö PREPROCESS / TRAIN\")\n",
        "print(\"CUDA:\", torch.cuda.is_available())\n"
      ],
      "metadata": {
        "id": "adjzcBmehumU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from pathlib import Path\n",
        "\n",
        "SRC_DIR = \"/content/wavs\"\n",
        "DST_DIR = \"/content/Retrieval-based-Voice-Conversion-WebUI/dataset_speaker\"\n",
        "os.makedirs(DST_DIR, exist_ok=True)\n",
        "\n",
        "filelist_path = os.path.join(DST_DIR, \"filelist.txt\")\n",
        "filelist = []\n",
        "\n",
        "TARGET_SR = 44100\n",
        "SPEAKER = \"spk1\"\n",
        "\n",
        "print(\"‚ÑπÔ∏è –ù–∞—á–∏–Ω–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–π preprocess WAV...\")\n",
        "\n",
        "for i, fname in enumerate(sorted(os.listdir(SRC_DIR))):\n",
        "    if not fname.lower().endswith(\".wav\"):\n",
        "        continue\n",
        "\n",
        "    src_path = os.path.join(SRC_DIR, fname)\n",
        "    y, sr = librosa.load(src_path, sr=TARGET_SR, mono=True)\n",
        "    y = y / max(abs(y)) * 0.99  # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è\n",
        "\n",
        "    dst_fname = f\"{SPEAKER}_{i:04d}.wav\"\n",
        "    dst_path = os.path.join(DST_DIR, dst_fname)\n",
        "    sf.write(dst_path, y, TARGET_SR)\n",
        "\n",
        "    filelist.append(f\"{dst_path}|{SPEAKER}\")\n",
        "\n",
        "# –°–æ–∑–¥–∞—ë–º filelist.txt\n",
        "with open(filelist_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(filelist))\n",
        "\n",
        "print(f\"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(filelist)} —Ñ–∞–π–ª–æ–≤\")\n",
        "print(f\"‚úÖ filelist.txt —Å–æ–∑–¥–∞–Ω –≤ {filelist_path}\")\n",
        "print(\"üî• Preprocess –∑–∞–≤–µ—Ä—à—ë–Ω. –î–∞–Ω–Ω—ã–µ –≥–æ—Ç–æ–≤—ã –∫ feature extraction / training\")\n"
      ],
      "metadata": {
        "id": "L_FFr_u6khmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "from pathlib import Path\n",
        "\n",
        "# –ü—É—Ç–∏\n",
        "DATASET_DIR = \"/content/Retrieval-based-Voice-Conversion-WebUI/dataset_speaker\"\n",
        "FEATURE_DIR = os.path.join(DATASET_DIR, \"features\")\n",
        "os.makedirs(FEATURE_DIR, exist_ok=True)\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"‚ÑπÔ∏è Feature extraction –Ω–∞ {DEVICE}\")\n",
        "\n",
        "# –°–∫–∞—á–∏–≤–∞–µ–º HuBERT\n",
        "HUBERT_PATH = \"/content/hubert_base.pt\"\n",
        "if not os.path.exists(HUBERT_PATH):\n",
        "    print(\"‚ÑπÔ∏è –°–∫–∞—á–∏–≤–∞–µ–º HuBERT base...\")\n",
        "    !wget -O {HUBERT_PATH} \"https://huggingface.co/s3prl/hubert-base-ls960/resolve/main/hubert_base.pt\"\n",
        "    print(\"‚úÖ HuBERT —Å–∫–∞—á–∞–Ω\")\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ s3prl hubert\n",
        "hubert_model = torch.hub.load(\"s3prl/s3prl\", \"hubert\", source=\"github\")\n",
        "hubert_model.eval().to(DEVICE)\n",
        "\n",
        "# –ë–µ—Ä—ë–º –≤—Å–µ WAV\n",
        "wav_files = sorted([f for f in os.listdir(DATASET_DIR) if f.endswith(\".wav\")])\n",
        "if not wav_files:\n",
        "    raise FileNotFoundError(\"‚ùå WAV —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ dataset_speaker!\")\n",
        "\n",
        "def extract_feature(wav_path):\n",
        "    waveform, sr = torchaudio.load(wav_path)\n",
        "    if sr != 16000:\n",
        "        waveform = torchaudio.functional.resample(waveform, sr, 16000)\n",
        "    waveform = waveform.mean(dim=0, keepdim=True)  # –º–æ–Ω–æ\n",
        "    with torch.no_grad():\n",
        "        feats = hubert_model(waveform.to(DEVICE))\n",
        "    return feats.squeeze(0).cpu()\n",
        "\n",
        "# –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º .pt —Ñ–∞–π–ª—ã\n",
        "for wav_name in wav_files:\n",
        "    wav_path = os.path.join(DATASET_DIR, wav_name)\n",
        "    feature_path = os.path.join(FEATURE_DIR, wav_name.replace(\".wav\", \".pt\"))\n",
        "    if os.path.exists(feature_path):\n",
        "        continue\n",
        "    feats = extract_feature(wav_path)\n",
        "    torch.save(feats, feature_path)\n",
        "    print(f\"‚úÖ {wav_name} ‚Üí {feature_path}\")\n",
        "\n",
        "print(f\"üî• Feature extraction –∑–∞–≤–µ—Ä—à—ë–Ω. –í—Å–µ —Ñ–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {FEATURE_DIR}\")\n"
      ],
      "metadata": {
        "id": "QlApYdMElqWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# –°–∫–∞—á–∏–≤–∞–µ–º —á–µ—Ä–µ–∑ huggingface-cli (–∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –Ω–µ –Ω—É–∂–Ω–∞ –¥–ª—è –ø—É–±–ª–∏—á–Ω–æ–π –º–æ–¥–µ–ª–∏)\n",
        "!mkdir -p /content/hubert\n",
        "!wget -O /content/hubert/hubert_base.pt \"https://huggingface.co/facebook/hubert-base-ls960/resolve/main/hubert_base.pt\"\n"
      ],
      "metadata": {
        "id": "3p9qg5KXl-yY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Retrieval-based-Voice-Conversion-WebUI/infer/modules/train/extract_feature.py \\\n",
        "    /content/Retrieval-based-Voice-Conversion-WebUI/dataset_speaker \\\n",
        "    /content/hubert/hubert_base.pt\n"
      ],
      "metadata": {
        "id": "2MrqNSnNmElI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}